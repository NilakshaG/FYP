# -*- coding: utf-8 -*-
"""Nila-FYP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dr0EYEFvi-PSrH4ATdJFET0aMi69NBFu
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

# Load dataset
data_path = "efficiency_labeled_with_overall.csv"
df = pd.read_csv(data_path)

# Display basic information
print("Dataset Information:\n")
df.info()

# Check for missing values
print("\nMissing Values per Column:\n")
print(df.isnull().sum())

# Visualizing missing values
plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cmap='viridis', cbar=False, yticklabels=False)
plt.title("Missing Values Heatmap (Before Imputation)")
plt.show()

# Iterate through each column and print its values
for column in df.columns:
    print(f"Column: {column}")
    print(df[column])
    print("-" * 50)

# Remove the columns which is not relevant for efficiency prediction
df= df.drop(columns=["Merch", "Comment/Material Code"])

# Remove the columns which filled with same values
df= df.drop(columns=["Single/ Staggered", "Fleece","Block cut","Vlok"])

# Remove the column which have no any values
df= df.drop(columns =["Manual Efficiency Override"])

# Identify numerical and categorical columns
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()

# Separate numerical and categorical dataframes
num_cols_df = df[num_cols]
cat_cols_df = df[cat_cols]

print("\nDuplicate Rows Count:", df.duplicated().sum())
df.drop_duplicates(inplace=True)

# Apply Multivariate Imputation by Chained Equations (MICE) to numerical data
mice_imputer = IterativeImputer(max_iter=10, random_state=42)
num_cols_df_imputed = pd.DataFrame(mice_imputer.fit_transform(num_cols_df), columns=num_cols)

# Concatenate numerical and categorical dataframes
df = pd.concat([num_cols_df_imputed, cat_cols_df], axis=1)

# Verify missing values after treatment
print("\nMissing Values After MICE Imputation:\n")
print(df.isnull().sum())

# Identify columns to process for outliers
excluded_cols = ["Estimated Volume for the Season"]
num_cols_to_process = [col for col in num_cols if col not in excluded_cols]

# Boxplots before outlier treatment
for col in num_cols_to_process:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot of {col} (Before Outlier Treatment)")
    plt.show()

# Outlier treatment using IQR method
def remove_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])

for col in num_cols_to_process:
    remove_outliers(df, col)

# Boxplots after outlier treatment
for col in num_cols_to_process:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot of {col} (After Outlier Treatment)")
    plt.show()

# Distribution of numerical columns
for col in num_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f"Distribution of {col}")
    plt.show()

# Create new columns based on threshold values
df["Estimated_Volume_Binary"] = np.where(df["Estimated Volume for the Season"] < 280000, 1, 0)
df["Production_Lead_Time_Binary"] = np.where(df["Production Lead Time"] < 18, 1, 0)
df["Fabric_Lead_Time_Binary"] = np.where(df["Fabric Lead Time"] < 76, 1, 0)
df["Unpaid_Dev_Samples_Binary"] = np.where(df["No.of unpaid dev samples"] < 17, 1, 0)
df["Total_Standard_Hours_Binary"] = np.where(df["Total Standard Hours"] < 70000, 1, 0)
df["EPH_Reduced_Binary"] = np.where(df["EPH - Reduced SMV"] > 18, 1, 0)
df["SMV_Reduced_Binary"] = np.where(df["SMV - Reduced"] > 11, 1, 0)
df["OH_Binary"] = np.where(df["Total Overhead"] < 550000, 1, 0)

df

# Check correlation matrix

plt.figure(figsize=(10, 6))
sns.heatmap(df[num_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Feature Correlation Heatmap")
plt.show()

# Since this have correlation values very close to 0,
# means that there are no any relationship and they works like independent variables

# Encoding Overall Efficiency column to 1 and 0 s

df["Overall Efficiency"] = df["Overall Efficiency"].map({"Overall Efficient": 2, "Overall Low Efficient": 1, "Overall Inefficient": 0})

df

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

